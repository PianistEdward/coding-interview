# Java并发编程

------------------------------------------《并发编程的艺术》读书笔记

资料：

[深入理解多线程](https://www.hollischuang.com/archives/tag/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%A4%9A%E7%BA%BF%E7%A8%8B)

[深入理解Java并发编程](https://www.hollischuang.com/archives/tag/%e6%b7%b1%e5%85%a5%e7%90%86%e8%a7%a3java%e5%b9%b6%e5%8f%91%e7%bc%96%e7%a8%8b)

[Synchronized解析——如果你愿意一层一层剥开我的心 - 掘金](https://juejin.cn/post/6844903918653145102)



## 一、并发编程的挑战

### 1.1 上下文切换

1.1 测试上下文切换次数和时长

Lmbench3可以测量上下文切换的时长。

vmstat可以测量上下文切换的次数：CS（Content Switch）表示上下文切换的次数。

### 1.2 死锁

死锁排查：jps+jstack

`jps -l `

`jstack -l PID`

`jstack PID| grep 'waiting to lock'`

也可以用jdk自带的jconsole，jvisualvm，开源工具arthas。

## 二、底层实现原理

CPU知识准备：

- 寄存器

  - 存储内存地址类寄存器：程序计数器，基址寄存器，变址寄存器。

  - 存储非内存地址寄存器：累加寄存器，通用寄存器，标志寄存器。

- 代码在CPU执行流程


### 2.1 volatile

volatile不会引起线程上下文切换和调度。

1、CPU术语

内存屏障、缓存行、原子操作、缓冲行填充、缓存命中、写命中、写缺失。

- 内存屏障：一组处理器指令，用于实现对内存操作的顺序限制。
- 缓存行：cache line ，缓存中可以分配的最小存储单位。

2、lock前缀的指令

- 将当前处理器缓存行的数据写回到系统内存

- 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效


3、缓存一致性协议

4、追加64个字节，优化volatile性能

- 一个对象的引用占4个字节。

- L1、L2或L3缓存的高速缓存行是64个字节宽，不支持部分填充缓存行。

### 2.2 synchronized

Java中的每一个对象都可以作为锁。

- 对于普通同步方法，锁是当前实例对象。
- 对于静态同步方法，锁是当前类的Class对象。
- 对于同步方法块，锁是Synchonized括号里配置的对象。

JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现的，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。

monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。

2.2.1 Java对象头

synchronized用的锁是存在Java对象头里的。

Java对象头的存储结构？

2.2.2 锁的升级与对比

JDK1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状
态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级。

1）偏向锁

什么是偏向锁？

偏向锁的获得？

偏向锁的撤销？

JVM参数关闭偏向锁。

2）轻量级锁

3）重量级锁

不同锁的适用场景？优缺点？

### 2.3 原子操作

1、概念：

- 缓存行：cache line，缓存操作的最小单位

- CPU流水线：CPU pipeline

- 内存顺序冲突。伪共享会引发内存顺序冲突。出现内存顺序冲突时，CPU必须清空流水线（CPU pipeline）


2、处理器实现原子操作：

- 基本的内存操作：保证原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。

- 复杂内存操作：不能保证原子性。处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。

  1. 总线锁：使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。

  2. 缓存锁：内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效。

     - 处理器不会使用缓存锁定的情况：

       1)、当操作的数据不能被缓存在处理器内部、或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。

       2)、有些处理器不支持缓存锁定。

3、Java实现原子操作

- 锁

- 循环CAS：JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。

  - CAS实现原子操作三大问题：

    1)、ABA问题。解决思路就是使用版本号。

    2)、循环时间长开销大。

    3)、只能保证一个共享变量的原子操作。对多个共享变量操作时，循环CAS就无法保证操作的原子性。

## 三、Java内存模型

### 3.1 Java内存模型的基础

3.1.1 两个关键问题

线程之间如何通信、如何同步？

通信：线程之间以何种机制来交换信息。

同步：程序中用于控制不同线程间操作发生相对顺序的机制。

3.1.2 Java内存模型的抽象结构

Java线程之间的通信由Java内存模型（JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。

从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。

3.1.3 从源代码到指令序列的重排序

- 编译器重排序

  JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。

- 处理器重排序

  JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障，通过内存屏障指令来禁止特定类型的处理器重排序。

3.1.4 并发编程模型的分类

为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。

JMM把内存屏障指令分为4类，其中使用最广泛的是StoreLoad Barriers。

3.1.5 happens-before简介

JSR-133使用happens-before的概念来阐述操作之间的内存可见性。

在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。

happens-before规则如下：

- 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
- 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
- volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
- 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。

### 3.2 重排序

3.2.1 数据依赖性

如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。

3.2.2 as-if-serial语义

as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）
程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。

3.2.3 程序顺序规则

如果A happens-before B，JMM并不要求A一定要在B之前执行。JMM仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。